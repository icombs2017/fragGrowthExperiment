---
title: "Surface Area Analysis"
author: "Ian Combs -- icombs@mote.org"
output:
  html_document:
    theme: flatly
    code_folding: show
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_doctument:
      toc: yes
      toc_depth: 3
---
```{r, setup, include = FALSE}
knitr::opts_chunk$set(warning = FALSE, fig.align = 'left')
knitr::opts_knit$set(root.dir = "../data")
options(width = 88)
library(magrittr)
```





### version: `r Sys.Date() %>% format(format="%B %d, %Y")`

<!-- this is where the DOI would go  [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3675991.svg)](https://doi.org/10.5281/zenodo.3675991)
-->


#### [GitHub repository](https://github.com/icombs2017/fragGrowthExperiment.git){target="_blank"}
###

***
This is the working analysis pipeline to analyze data generated from 3D models of micro-fragmented coral colonies and larger frags to assess differences in growth rates between microfragments and natural growth. 

***

### All analyses performed with R version `r getRversion()`


# Basic setup of R environment
***
## Loading required packages
For the following analyses we will require the use of a number of different R packages. Most of which can be sourced from CRAN, but some must be downloaded from GitHub. We can use the following code to load in the packages and install any packages not previously installed in the R console. 


```{r,packages, include = TRUE, message = FALSE, warning = FALSE, results = 'hide'}
if (!require("pacman")) install.packages("pacman")
pacman::p_load("ggplot2", "googlesheets4", "dplyr", "officer","reshape2", "stringr", "flextable", "gridExtra", "ggpubr", "Rmisc", "rcompanion", "RColorBrewer", "vegan", "googledrive", "gdata", "readxl", "DescTools","patchwork", "FSA")

#IF YOU WANT TO RUN PAIRWISE PERMANOVA REMEMBER TO INSTALL PAIRWISE ADONIS

```



# Importing Data
***
## We are downloading this dataset from our GoogleDrive folder. We will be using the package `googledrive`. Each GoogleDrive file has a unique ID that does not change throughout the lifespan of the document, even if the file name is changed. This ID is housed in the file's URL. 
Example: docs.google.com/spreadsheets/d/FILE_ID_GOES_HERE/other_information/. Below you will copy and paste that into the function `drive_download` within `as_id`. This will save the file locally in the specified path (in this case our data folder) and you will import the folder as you normally would. Downloading it this way decreases the potential human error when downloading, moving folders, renaming, saving etc and ensures that the most up to date file is being utilized. 



```{r, loadingData, include = TRUE}


drive_download(
  as_id("1C1deEPnb07YcvbEngx_OV3Xl-C740sBefoaum154OyY"),
  path = "../data/saDataset.xlsx", 
  overwrite = TRUE)

sa <- read_excel("../data/saDataset.xlsx", sheet = 2)

sa


```



## Now I am just tidying up my dataset, I am combining two columns, **species** and **genotype** into a column **geno** using the `paste0` function, cleaning up the raw dataset to only include my species of concern using multiple functions from the package `dplyr`, and changing the class of some variables to factors using the function `as.factor()` for easier manipulation down the road. 


```{r, dataManipulation, include = TRUE}


saClean <- sa %>% 
  select("timepoint", "species", "genotype","id","trial","treatment","SA")




saClean$timepoint <- as.factor(saClean$timepoint)

saClean$species <- as.factor(saClean$species)

saClean$id <- as.factor(saClean$id)

saClean$trial <- as.factor(saClean$trial)

saClean$treatment <- as.factor(saClean$treatment)



head(saClean)



```
### Here we are breaking the data apart into frags and wilds, combinging the frags from each trial, putting the data back together, and then calculating percent change of surface area between the first and last timepoint. We are using a number of functions from the package `dplyr` as well as the function `dcast()` to recombine data from the package `reshape2` 


```{r, calculatingPercentChange, include = TRUE }


saFrag <- saClean %>%
  select(timepoint, species, id, treatment, SA) %>%
  dplyr::filter(treatment %in% 'frag') %>%
  dplyr::group_by(id,timepoint) %>%
  dplyr::summarise(sum(SA))


saWild <- saClean %>%
  dplyr::filter(treatment %in% 'wild') %>%
  select(timepoint, species, id, treatment, SA)



 
saCombo <- left_join(saFrag, saWild, by = c("timepoint","id"), copy = FALSE) %>%
  dplyr::rename(fragSA = `sum(SA)`) %>%
  dplyr::rename(wildSA = SA) %>% 
  select(id, timepoint, fragSA, wildSA)

saCombo <- bind_rows(saFrag,saWild)

saFinal <- saCombo %>%
  dplyr::filter(timepoint %in% c("0","4")) %>%
  select(c('timepoint','id','treatment','surfaceArea'))



saChange <- dcast(saFinal, geno+ID~timePoint) 









saDiff <- saCombo %>% 
  group_by(id) %>% 
  summarise()

 


```